---
- name: "Upgrade Manager"
  when: inventory_hostname in groups["manager"]
  block:
    - name: "Get the installed packages facts"
      ansible.builtin.package_facts:
        manager: "auto"

    - name: "Print kubernetes packages version"
      ansible.builtin.debug:
        msg:
          - "{{ ansible_facts.packages.kubelet[0].version }}"
          - "{{ ansible_facts.packages.kubeadm[0].version }}"
          - "{{ ansible_facts.packages.kubectl[0].version }}"

    - name: "Remove version lock from kubernetes packages"
      community.general.yum_versionlock:
        state: absent
        name:
          - "{{ item }}"
      with_items: "{{ versionlock_k8s_packages }}"

    - name: "Drain cluster head node -> {{ inventory_hostname }}"
      ansible.builtin.shell: |
        kubectl drain {{ inventory_hostname }} --ignore-daemonsets --delete-local-data
      register: drain_node_register
      changed_when: drain_node_register.rc != 0

    - name: "Verify the upgrade plan"
      ansible.builtin.shell: |
        kubeadm upgrade plan --allow-experimental-upgrades --ignore-preflight-errors=all
      register: upgrade_plan_register
      changed_when: upgrade_plan_register.rc != 0

    - name: "Upgrade Manager Node Packages with version {{ item }}"
      ansible.builtin.dnf:
        name: "{{ item }}"
        disable_excludes: kubernetes
        update_cache: true
      with_items: "{{ upgrade_k8s_packages }}"

    - name: "Pull kubeadm config images"
      ansible.builtin.shell: |
        kubeadm config images pull
      register: pull_images_register
      changed_when: pull_images_register != 0

    - name: "Upgrading k8s cluster to {{ item }}"
      ansible.builtin.shell: |
        kubeadm upgrade apply v"{{ item }}" --allow-experimental-upgrades --ignore-preflight-errors=all --force --yes
      register: upgrade_register
      changed_when: upgrade_register != 0
      failed_when: "'FAILED' in upgrade_register.stderr"

    - name: "Reload Daemon and kubelet"
      ansible.builtin.systemd:
        state: restarted
        daemon_reload: true
        name: kubelet

    - name: "Uncordon Manager Node"
      ansible.builtin.shell: |
        kubectl uncordon {{ inventory_hostname }}
      register: uncordon_register
      changed_when: uncordon_register != 0

    - name: Wait for all oim-node pods become created
      ansible.builtin.shell: "kubectl get po --namespace=kube-system --selector tier=control-plane --output=jsonpath='{.items[*].metadata.name}'"
      register: oim_pods_created
      until: item in oim_pods_created.stdout
      retries: "{{ retries_count }}"
      delay: "{{ delay_time }}"
      changed_when: oim_pods_created != 0
      with_items:
        - etcd
        - kube-apiserver
        - kube-controller-manager
        - kube-scheduler

    - name: "Print updated kubernetes packages version"
      ansible.builtin.debug:
        msg:
          - "{{ ansible_facts.packages.kubelet[0].version }}"
          - "{{ ansible_facts.packages.kubeadm[0].version }}"
          - "{{ ansible_facts.packages.kubectl[0].version }}"

    - name: "Add version lock on kubernetes packages from being updated"
      community.general.yum_versionlock:
        state: present
        name:
          - "{{ item }}"
      with_items: "{{ versionlock_k8s_packages }}"

    - name: "Clean metadata and update yum modules"
      ansible.builtin.shell: yum clean metadata && yum clean all && yum makecache
      changed_when: true

    - name: "Success Message"
      ansible.builtin.debug:
        msg: "SUCCESS! Your cluster are upgraded to {{ item }}. Enjoy!"
